2019/03/20
1.Finish Tanji3 DLA documents writing, include control module of LPE, control module of APE and the top module of control. The documents will be uploaded.
2.Study base 2 FFT algorithm that extracted by frequncy and base 4 FFT algorithm that extracted by time(base 4 FFT algorithm further reduce the computation complexity compared with base 2 FFT algorithm) in order to have a deeper understanding on Tingshua's Paper on ISSCC2019.
  a.Based on CirCNN
  b.Use FFT to compute convolution in CirCNN model
3.Read ISSCC2019 Paper "An 11.5TOPS/W 1024-MAC BUtterfly Structure Dual-Core Sparsity-Aware Neural Processing Unit in 8nm Flagship Mobile Soc":
  a.Moving Output Feature Maps to compute convolution
  b.Butterfly-Structure Dual-Core Accelerator
  c.Sparsity-Aware Computing:Using Feature Selection
4.Prepare the slide about accelerator based on Winograd Convolution.The Slides Will be uploaded.
2019/03/28
1.Read Paper "FPGA based efficient on-chip memory for image processing algorithms" to learn several main data access policies for image processing algorithms.
  a.Prposed a sub-bank Dual Port memory architecture based on Single Port SRAM which supports several main data access policies.
  b.Confused with its clock generation block and memory control unit.
2.Read Tingshua's Paper on ISSCC 2019, got its main idea about dataflow and methods to  efficiently do RFFT(The inputs are real numbers):
  a.Use CirCNN model proposed on Micro 2017.
  b.Using radix-2 DIT(decimation in time) algorithm and use 7-stage butterfly architecture and each stage contains 32 basic butterfly units to support up to 128-point FFT.
  c.Using "doubling algorithm" to avoid redundant operations in CFFT computing.
  But there are some details that I don't understand clearly:
  a.Why the weight matrixes are block-circulant matrixes after rearranging?
  b.Details about how to realize 1-to-12b data-width supporting.
  c.Details about HBST-TRAM.
  I will do a representation when I completely understand this paper.
3.Read Paper "A Pipelined FFT Architecture for Real-Valued Signals" to learn some architectures for real-valued signals.
4.Modify the slides of "Winograd Convolution", the representation will da tonight.
2019/04/04
1.Attend a lecture about accelerating ddep convolutional network inferences at algorithm level given by Bei Yu from CUHK on Friday afternoon.
2.Scan KAIST's ISSCC Paper about LNPU, an atchitecture aiming to accelerate DNN's training at edge. Need to study knowledge about training for further understanding.
  a.Use mixed precision(FP8 and FP16) to improve enegy efficiency with slight accuracy loss.
  b.Support zero-skipping operation in computing core.
3.Learn speech given by Bert Moons on ISSCC 2019, the topic is "Enabling Embedded Intelligence: Application, architecture and design solutions".
4.Ask for leave from Tuesday to Thursday.
2019/04/11
1.Study and understand some details of Tingshua's ISSCC2019 Paper which confused me during previous reading:
  a.Understand the method which makes the weight matrix after reformulation still be a block-circulant matrix
  b.The data-resue pattern during element-wise multiplication
  c.Serial-to-parallel transformation during dataflow
2.Find some new details that don't appear in slides and paper
  a.Because some twiddle factors can't be represented preciselyï¼Œso FFT may bring error.
  b.The method of rounding between stages.
3.Write a block to do 64-point fft using radix-2 DIT algorithm for further research and modification. Not complete.
2019/04/18
1.Read paper "CircConv: A Structured Convolution with Low Complexity":
  a.Use circulant tensor for weight(the same as CirCNN does I think but use another method to explain the structured tensor)
  b.Propose a method to training circulant CNN from a pre-trained model
2.Read paper "Optimizing Bit-Serial Matrix Multiplication for Reconfigurable Computing":
  a.Intoduce a framework named "BISMO" to dp bit-serial matrix multiplication in order to support variable-precision computation proposed in their previous work
  b.Modify original Dot Product Unit(DPU) with matirx compression techniques to decrease the height of the input data at the cost of width increation.
  c.Modify the shifter in DPU by change the computation order so that the new shifter only need to support one type(shift left by one bit) of shift opertion
  d.Proposed bit-parallel to bit-serial transformaiton to reshape the data stored in main memory for efficient access.
  e.The software of "BISMO" framework still need to study.
3.Study math about matrix computation to find some tecniques to accelerate matrix computation(use the book writen by Gene H.Golub and Charles F.Van Loan)
2019/04/25
1.Think how to eliminate redundant operations during transformation of input feature map tile in Winograd convolution.
  a.Because there exists overlapping between neighboring input feature map tiles
2.Think how to use an unified computing architecture to support both complex-number matrix multiplication and real-number matrix multiplication.
3.Think if there exists an unified architecture supporting both radix-2 FFT and radix-4 FFT
2019/05/09
1.Read Paper about PERMDNN, which uses structured matrix-based approach like CirCNN to bring regularity to sparse  weight matrix.
  a.Make the weight matrices of the DNN model consist of multiple permuted diagnal sub-matrices.
  b.Permuted diagnal matrix require less storage than unstructured matrix becasue its its row index can be got by its column index.
  c.More flexibility than CirCNN because PERMCNN dose not have any restrictions on the size of block permuted diagnal matrix.
  d.Avoid computation between complex numbers
2.Read Paper about how to pack sparse CNNs for efficient systolic array implementations
  a.Use column combining to make sparse weight matrix become dense.
  b.Don't know how to combine the correspondingrows of input feature map matrix.
  c.Use bit-serial MAC.
